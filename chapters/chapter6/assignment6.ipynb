{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12a6f131",
   "metadata": {},
   "source": [
    "# Chapter 6 Assignment (NOT FINALIZED)\n",
    "\n",
    "Please fill in blanks in the *Answer* sections of this notebook. To check your answer for a problem, run the Setup, Answer, and Result sections. DO NOT MODIFY SETUP OR RESULT CELLS. See the [README](https://github.com/mortonne/datascipsych) for instructions on setting up a Python environment to run this notebook.\n",
    "\n",
    "Write your answers for each problem. Then restart the kernel, run all cells, and then save the notebook. Upload your notebook to Canvas.\n",
    "\n",
    "If you get stuck, read through the other notebooks in this directory, ask us for help in class, or ask other students for help in class or on the weekly discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d393dd4",
   "metadata": {},
   "source": [
    "## Problem: analyzing free recall data (12 points)\n",
    "\n",
    "The file `data/gen_recall.txt` has data from a (fake) free recall study. In free recall studies, participants study a list of words (here, there were 12 words) and then attempt to recall as many words as they can remember, in any order. For example, someone might study the list PIE, CAKE, KITE, BONE, GUARDIAN, THIMBLE, HAYSTACK, ZOO, DISHWASHER, TAPE, MONSTER, SWAMP, then recall SWAMP, MONSTER, DISHWASHER, PIE.\n",
    "\n",
    "In the recall data, there are 100 participants. The data are coded as a matrix with 100 rows (one for each participant) and 12 columns (one for each word). The words are in *serial position* order; that is, the first presented word is in the first column, the second presented word is in the second column, etc. In each row and column of the data, there is either a 0, which indicates that the word at that position was not recalled, or a 1, which indicates that the word was recalled.\n",
    "\n",
    "Information about the 100 participants is stored in the file `data/gen_participants.txt`, which indicates the identifier of each participant and their age in years.\n",
    "\n",
    "### Load data and calculate recall by serial position (4 points)\n",
    "\n",
    "Load the data from `data/gen_recall.txt` into a NumPy array using `np.loadtxt`. Calculate the probability of recall for each serial position, based on mean recall at each serial position, and place the result in a NumPy array called `p_recall`. Probability of recall can range from 0 (the item at the position was not recalled by any participants) to 1 (the item was recalled by all participants), or anywhere between, such as 0.5 (the item was recalled by 50% of participants).\n",
    "\n",
    "Below, write your code to load the data (1 point) and calculate probability of recall (2 points), and edit the markdown cell to write your answer to the question (1 point).\n",
    "\n",
    "### Calculate recall by serial position group (4 points)\n",
    "\n",
    "Write a function called `bin_recall` that takes a NumPy array with the probability of recall by serial position and calculates the mean probability of recall for each serial position bin, defined as early: 1-4, middle: 5-8, and late: 9-12. Your function should return a dictionary with keys called `\"early\"`, `\"middle\"`, and `\"late\"`, with the mean probability of recall for each serial position bin. Call your function with the `p_recall` variable you calculated previously and save the result to a variable called `p_recall_by_bin`.\n",
    "\n",
    "Below, write the code to define your function (2 points) and use it to calculate probability of recall for each serial position bin (1 point). Then edit the markdown cell to write your answers to the questions (1 point).\n",
    "\n",
    "### Calculate participant statistics (4 points)\n",
    "\n",
    "When reporting results from a study, you should provide statistics on the age distribution of the participants.\n",
    "\n",
    "The file `data/gen_participants.txt` has a matrix with 100 rows (one for each participant) and two columns. The first column indicates the identifier of each participant. The second column indicates the age of the participant in years.\n",
    "\n",
    "Calculate the mean (1 point), standard deviation (1 point), minimum (1 point), and maximum (1 point) age of the participants. Place the statistics in a dictionary called `age_stats` with keys called `\"mean\"`, `\"sd\"`, `\"min\"`, and `\"max\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1400a",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6a90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "p_recall = None\n",
    "bin_recall = None\n",
    "p_recall_by_bin = None\n",
    "age_stats = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c52a8f",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be93184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48c9c5",
   "metadata": {},
   "source": [
    "> What was the probability of recall for serial position 4?\n",
    "\n",
    "[answer here]\n",
    "\n",
    "> Does it seem like there was a primacy effect, where items early in the list (serial positions 1-4) were recalled more than the items in the middle of the list (serial positions 4-8)? Why or why not?\n",
    "\n",
    "[answer here]\n",
    "\n",
    "> Does it seem like there was a recency effect, where items late in the list (serial positions 9-12) were recalled more than items in the middle of the list (serial positions 5-8)? Why or why not?\n",
    "\n",
    "[answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eac9b9",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a1b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [p_recall, bin_recall, p_recall_by_bin, age_stats]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    print(p_recall)\n",
    "    print(p_recall_by_bin)\n",
    "    print(age_stats)\n",
    "    \n",
    "    # this should not throw any errors\n",
    "    assert len(p_recall) == 12\n",
    "    assert np.all((p_recall >= 0) & (p_recall <= 1))\n",
    "    np.testing.assert_array_equal(\n",
    "        p_recall,\n",
    "        np.array([0.31, 0.16, 0.15, 0.11, 0.12, 0.09, 0.17, 0.15, 0.15, 0.24, 0.39, 0.57])\n",
    "    )\n",
    "\n",
    "    binned = bin_recall(p_recall)\n",
    "\n",
    "    assert isinstance(p_recall_by_bin, dict)\n",
    "    for val in p_recall_by_bin.values():\n",
    "        assert val >= 0 and val <= 1\n",
    "    assert p_recall_by_bin[\"early\"] == 0.1825\n",
    "    assert p_recall_by_bin[\"middle\"] == 0.1325\n",
    "    assert p_recall_by_bin[\"late\"] == 0.3375\n",
    "\n",
    "    assert isinstance(age_stats, dict)\n",
    "    assert round(age_stats[\"mean\"], 1) == 24.1\n",
    "    assert round(age_stats[\"sd\"], 1) == 4.3\n",
    "    assert age_stats[\"min\"] == 11\n",
    "    assert age_stats[\"max\"] == 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf9d33",
   "metadata": {},
   "source": [
    "## Problem (graduate students): central tendency (4 points)\n",
    "We talked about two measures of central tendency, the mean and the median. We also talked about dealing with missing data, as represented by `NaN` values.\n",
    "\n",
    "Write a function called `central_tendency` that calculates measures of central tendency. It should take in three inputs: `x`, `measure`, `exclude_nan`, and return the specified measure for the data in `x`.\n",
    "\n",
    "`x` is an array of numbers.\n",
    "\n",
    "`measure` may be either `\"mean\"` or `\"median\"`. The function should raise a `ValueError` with the message `\"Error: unknown measure\"` if some other input is given. \n",
    "\n",
    "`exclude_nan` is either `True` or `False`. If `True`, then the measure should be calculated after excluding `NaN` values. If `False`, then the measure should be calculated based on all values, even if there are `NaN` values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81da92c",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435c80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_tendency = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff75262",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df2d41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b309bfb",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24999e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [central_tendency]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should not throw any errors\n",
    "    x = np.array([5, np.nan, 9, 10, 1, 2, 3, 22])\n",
    "    assert round(central_tendency(x, \"mean\", True), 2) == 7.43\n",
    "    assert central_tendency(x, \"median\", True) == 5\n",
    "    assert np.isnan(central_tendency(x, \"mean\", False))\n",
    "    assert np.isnan(central_tendency(x, \"median\", False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6a662",
   "metadata": {},
   "source": [
    "## Problem (graduate students): simulating behavioral responses (4 points)\n",
    "[Signal detection theory](https://www.cns.nyu.edu/~david/handouts/sdt/sdt.html) is a general framework for simulating detection of a some sort of signal. For example, when deciding if a word has been previously seen before, people may use some sort of memory strength signal, which tends to be stronger for previously seen words. In this model, people will say \"old\" to indicate that a word has been seen before if the strength exceeds some threshold or *criterion*, and otherwise they will say \"new\" to indicate that the word has not been seen before.\n",
    "\n",
    "Use NumPy to simulate 500 target trials and 500 lure trials, using `np.random.default_rng` with a seed of 42. The target memory strengths should be sampled from a normal distribution with a mean of 1 and a standard deviation of 0.5. The lure memory strength distribution should have a mean of 0 and a standard deviation of 0.5. Test two criterion values; criterion 1 will be 0.5, and criterion 2 will be 0.8. Increasing the criterion will reduce false alarms, but will also lower the hit rate.\n",
    "\n",
    "Randomly generate memory strength for 500 targets and 500 lures, and compare them to the criterion to determine what the behavioral response will be. In the simulation, any trial with strength greater than or equal to the criterion will generate the response \"old\", and any trial with strength less than the criterion will generate the response \"new\". Calculate hit rate and false alarm rate in your simulation, for each of the two criterion values.\n",
    "\n",
    "![Internal response probability of occurrence curves for noise-alone and signal-plus-noise trials. Since the curves overlap, the internal response for a noise-alone trial may exceed the internal response for a signal-plus-noise trial. Vertical lines correspond to the criterion response.](images/sdt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc41f0",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34535604",
   "metadata": {},
   "outputs": [],
   "source": [
    "lure_strength = None\n",
    "target_strength = None\n",
    "criterion1 = None\n",
    "criterion2 = None\n",
    "hit_rate1 = None\n",
    "false_alarm_rate1 = None\n",
    "hit_rate2 = None\n",
    "false_alarm_rate2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ebaecb",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdbd97bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748cf45",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7dd4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [\n",
    "    lure_strength, \n",
    "    target_strength, \n",
    "    criterion1, \n",
    "    criterion2, \n",
    "    hit_rate1, \n",
    "    false_alarm_rate1, \n",
    "    hit_rate2, \n",
    "    false_alarm_rate2,\n",
    "]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should make a histogram plotting your distributions\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.hist(lure_strength, alpha=0.8)\n",
    "    plt.hist(target_strength, alpha=0.8)\n",
    "    plt.vlines([criterion1, criterion2], 0, 200)\n",
    "    plt.xlabel(\"Memory strength\")\n",
    "\n",
    "    # this should print your variables\n",
    "    print(hit_rate1, false_alarm_rate1)\n",
    "    print(hit_rate2, false_alarm_rate2)\n",
    "\n",
    "    # this should not throw any errors\n",
    "    assert np.abs(hit_rate1 - 0.816) < 0.05\n",
    "    assert np.abs(false_alarm_rate1 - 0.138) < 0.05\n",
    "    assert np.abs(hit_rate2 - 0.654) < 0.05\n",
    "    assert np.abs(false_alarm_rate2 - 0.054) < 0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascipsych",
   "language": "python",
   "name": "datascipsych"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
